---
title: "508_final"
author: "Lan Xiao, Sisun Cheng"
date: "12/5/2021"
output: 
  html_document:
    toc: yes
    toc_float: TRUE
    code_folding: hide
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, results = FALSE, message = FALSE)
```

```{r library}
# set up
library(tidyverse)
library(sf)
library(lubridate)
library(tigris)
library(tidycensus)
library(gganimate)
library(viridis)
library(riem)
library(gridExtra)
library(knitr)
library(kableExtra)
library(RSocrata)
library(caret)
library(purrr)
library(FNN)
library(stargazer)
library(dplyr)
library(spatstat)
library(raster)
library(spdep)
library(grid)
library(mapview)


palette5 <- c("#eff3ff","#bdd7e7","#6baed6","#3182bd","#08519c")
palette4 <- c("#D2FBD4","#92BCAB","#527D82","#123F5A")
palette4_2 <- c("#83c8f9","#2984c3","#075d9a","#000066")
palette2 <- c("#6baed6","#08519c")

source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")

```

# Data wrangling

## Loading and wrangling data

```{r load data1}
# import SF neighborhood boundaries
neighborhood_sf <-
  st_read("local_data_source/Analysis Neighborhoods.geojson") %>%
  st_as_sf(coords = the_geom.coordinates, crs = 4326, agr = "constant") %>%
  st_transform('ESRI:102243')

# import meters data
meters <-
  read.socrata("https://data.sfgov.org/resource/8vzz-qzz9.json") %>%
  dplyr::select(post_id, street_id, longitude, latitude) %>%
  na.omit()

meters_sf <-
  meters %>%
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326, agr = "constant") %>%
  st_transform('ESRI:102243')

# import street park records in a specific time span
street_parks <- 
  read.socrata("https://data.sfgov.org/resource/imvp-dq3v.json?$where=session_start_dt between '2021-07-16T00:00:00' and '2021-08-27T00:00:00'") %>%
  na.omit() %>%
  merge(meters, by="post_id")

street_parks_sf <-
  street_parks %>%
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326, agr = "constant")  %>%
  st_transform('ESRI:102243')

# Off-street Parking
off_parking <-
  read.socrata("https://data.sfgov.org/resource/vqzx-t7c4.json") %>%
  dplyr::select(objectid, osp_id, street_address, owner, capacity, main_entrance_long, main_entrance_lat) %>%
  na.omit() 

off_parking_sf <-
  off_parking %>%
  st_as_sf(coords = c("main_entrance_long", "main_entrance_lat"), crs = 4326, agr = "constant") %>%
  st_transform('ESRI:102243')

# sidewalk width
sidewalk <-
  st_read("local_data_source/MTA.sidewalk_widths.geojson") %>%
  st_as_sf(coords = geometry, crs = 4326, agr = "constant") %>%
  mutate(sidewalk_f=as.numeric(as.character(sidewalk_f))) %>% 
  st_transform('ESRI:102243') 
sidewalk <- sidewalk %>% 
  filter(sidewalk_f<=0|sidewalk_f>40) %>% 
  mutate(sidewalk_f=13) %>% 
  rbind(
    filter(sidewalk,sidewalk_f>0&sidewalk_f<=40)
  ) 

# speed limits
street_speed <-
  st_read("local_data_source/Speed Limits per Street Segment.geojson") %>%
  st_as_sf(coords = geometry, crs = 4326, agr = "constant") %>%
  dplyr::select(cnn, st_type, speedlimit, street, from_st, to_st, geometry) %>%
  na.omit() %>%
  st_transform('ESRI:102243')
street_speed <- street_speed %>% 
  filter(speedlimit==0) %>% 
  mutate(speedlimit=25) %>% 
  rbind(
    filter(street_speed,speedlimit!=0&speedlimit!=99)
  ) %>% 
  rbind(
    street_speed %>% 
      filter(speedlimit==99) %>% 
      mutate(speedlimit=25)
  )
  

# incidents
incidents <-
  read.socrata("https://data.sfgov.org/resource/wg3w-h783.json?$where=incident_date between '2021-07-16T00:00:00' and '2021-08-27T00:00:00'") %>%
  dplyr::select(incident_date, incident_day_of_week, incident_id, report_type_code, 
                incident_category, police_district, analysis_neighborhood, latitude, longitude) %>%
  na.omit() %>%
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326, agr = "constant")%>%
  st_transform('ESRI:102243')

# census data
census_api_key("e79f3706b6d61249968c6ce88794f6f556e5bf3d", overwrite = TRUE)

SF_census <- 
  get_acs(geography = "tract", 
          variables = c("B01003_001", "B19013_001", 
                        "B02001_002", "B08013_001",
                        "B08012_001", "B08301_001", 
                        "B08301_010", "B01002_001"), 
          year = 2019, 
          state = '06',      # '06' for California
          geometry = TRUE, 
          county = '075',    # '075' for San Francisco county
          output = "wide") %>%
  rename(Total_Pop =  B01003_001E,
         Med_Inc = B19013_001E,
         Med_Age = B01002_001E,
         White_Pop = B02001_002E,
         Travel_Time = B08013_001E,
         Num_Commuters = B08012_001E,
         Means_of_Transport = B08301_001E,
         Total_Public_Trans = B08301_010E) %>%
  dplyr::select(Total_Pop, Med_Inc, White_Pop, Travel_Time,
                Means_of_Transport, Total_Public_Trans,
                Med_Age, GEOID, geometry) %>%
  mutate(Percent_White = White_Pop / Total_Pop,
         Mean_Commute_Time = Travel_Time / Total_Public_Trans,
         Percent_Taking_Public_Trans = Total_Public_Trans / Means_of_Transport) %>%
  st_transform('ESRI:102243')


# select the study regions
selected_nhoods_list = c("North Beach", "Russian Hill", "Nob Hill", "Chinatown",
                    "Financial District/South Beach", "Tenderloin", "South of Market")
selected_nhoods_sf <-
  neighborhood_sf %>%
  filter(nhood %in% selected_nhoods_list) %>%
  st_transform('ESRI:102243')

# total study area
study_area <-
  st_union(selected_nhoods_sf) %>%
  st_sf %>%
  st_transform('ESRI:102243')

```

```{r load data2}
# Street and Sidewalk Cleaning
street_clean <- read_csv("local_data_source/Street_and_Sidewalk_Cleaning_part.csv")
street_clean <- street_clean %>% 
  na.omit() %>% 
  filter(x!="0"&y!="0") %>% 
  st_as_sf(coords=c("y","x"), crs = 4326, agr = "constant") %>%
  dplyr::select(geometry) %>% 
  st_transform('ESRI:102243')

# Graffiti 
graffiti <- read.socrata("https://data.sfgov.org/resource/vg6y-3pcr.json?$where=requested_datetime between '2021-07-16T00:00:00' and '2021-08-27T00:00:00'") 
graffiti <- graffiti%>% 
  st_as_sf(coords = c("point.longitude", "point.latitude"), crs = 4326) %>% 
  filter(!grepl('Case is a Duplicate', status_notes)) %>% 
  dplyr::select(requested_datetime) %>%   
  na.omit() %>%
  st_transform('ESRI:102243')

# Blocked Bike Lanes and Double Parking
parking_violation <- read.socrata("https://data.sfgov.org/resource/ihm3-5gmc.json?$where=requested_datetime between '2021-07-16T00:00:00' and '2021-08-27T00:00:00'")
parking_violation <- parking_violation %>% 
  st_as_sf(coords = c("long", "lat"), crs = 4326) %>% 
  dplyr::select(requested_datetime) %>%   
  na.omit() %>%
  st_transform('ESRI:102243')


# Parking Management Districts
parking_district <- st_read("https://data.sfgov.org/resource/6vtc-mmhr.geojson") %>% 
  dplyr::select(pm_district_name) %>% 
  st_transform('ESRI:102243') 

#on street shared car parking
careshare_park <- read.socrata("https://data.sfgov.org/resource/g2t6-cyw6.json") 
careshare_park <- careshare_park %>% 
  dplyr::select(spaceid, point_x, point_y) %>% 
  na.omit %>% 
  st_as_sf(coords = c("point_x", "point_y"), crs = 4326, agr = "constant") %>%
  dplyr::select(geometry) %>% 
  st_transform('ESRI:102243')

# retail places
business <- st_read("local_data_source/Business_Locations.geojson")

# retail places
retail_spot <- business  %>% 
  filter(grepl("4400-4599",naic_code)) %>%
  dplyr::select(geometry) %>% 
  distinct()%>% 
  st_transform('ESRI:102243')

# food places
food_spot <- business  %>% 
  filter(grepl("7220-7229",naic_code)) %>% 
  dplyr::select(geometry) %>% 
  distinct()%>% 
  st_transform('ESRI:102243')
```

# Feature engineering

## Creating fishnet and joining with data

### Creating fishnet

```{r create fishnet}
# create the fishnet and count the parking number
fishnet_sf <- 
  st_make_grid(study_area,
               cellsize = 200, 
               square = TRUE) %>%
  .[study_area] %>%           
  st_sf() %>%
  mutate(uniqueID = rownames(.))
```

### Joining meter data into fishnet

```{r join meter data into fishnet}
# select the fishnet grids with meters
meter_net <- 
  dplyr::select(meters_sf) %>% 
  mutate(countMeters = 1) %>% 
  aggregate(., fishnet_sf, sum) %>%
  mutate(countMeters = replace_na(countMeters, 0),
         uniqueID = rownames(.),
         cvID = sample(round(nrow(fishnet_sf) / 8), 
                       size=nrow(fishnet_sf), replace = TRUE)) %>%
  filter(countMeters>0)

# plot fishnets with meters inside
ggplot() +
  geom_sf(data = meter_net, aes(fill = countMeters), color = NA) +
  scale_fill_viridis() +
  labs(title = "Fishnets with meters inside")+
    mapTheme()

meter_net <-
  meter_net %>%
  dplyr::select(geometry, uniqueID, countMeters)

```

### Joining parking data to the fishnet

```{r join parking data into fishnet}
parking_net <- street_parks_sf %>% 
  mutate(count=1) %>% 
  st_join(meter_net,.) %>% 
  st_drop_geometry() %>% 
  group_by(uniqueID) %>% 
  summarize(countPark = sum(count,na.rm = T)) %>% 
  left_join(meter_net) %>%
  st_sf()

ggplot() +
  geom_sf(data = parking_net, aes(fill = countPark), color = NA) +
  scale_fill_viridis() +
  labs(title = "Parking Counts in the fishnet")+
    mapTheme()

# plot parking information in grids with meters
ggplot(parking_net, aes(countPark)) + 
  geom_histogram(binwidth = 1, color = 'black', fill='white') +
  labs(title = "Parking Number Distribution in Each Fishnet Grid",
       subtitle = "2021-07-08 12:00-12:15")+
  plotTheme()

```

### Joining police incidents to the fishnet

```{r Joining police incidents to the fishnet}
# put police incidents into fishnet grids
incident_net <- incidents %>% 
  mutate(count=1) %>% 
  st_join(meter_net,.) %>% 
  st_drop_geometry() %>% 
  group_by(uniqueID) %>% 
  summarize(countIncident= sum(count,na.rm = T)) %>% 
  left_join(meter_net) %>%
  st_sf() 

ggplot() +
  geom_sf(data = incident_net, aes(fill = countIncident), color = NA) +
  scale_fill_viridis() +
  labs(title = "Police Incidents in Fishnet Grids")+
    mapTheme()
```

### Joining street speeds to the fishnet

```{r Joining street speeds to the fishnet}
speed_net <- st_join(meter_net,street_speed) %>% 
  dplyr::select(uniqueID, speedlimit) %>% 
  mutate(speedlimit=as.numeric(as.character(speedlimit))) %>% 
  st_drop_geometry() %>% 
  group_by(uniqueID) %>% 
  summarize(speedlimit=mean(speedlimit,na.rm=T)) %>% 
  left_join(meter_net) %>% 
  st_sf()


ggplot() +
  geom_sf(data = speed_net, aes(fill = speedlimit), color = NA) +
  scale_fill_viridis() +
  labs(title = "Street Speed in Fishnet Grids")+
    mapTheme()
```

### Joining sidewalk width to the fishnet

```{r Joining sidewalk width to the fishnet}
width_net <- st_join(meter_net,sidewalk) %>% 
  dplyr::select(uniqueID, sidewalk_f) %>% 
  st_drop_geometry() %>% 
  group_by(uniqueID) %>% 
  summarize(sidewalk_width=mean(sidewalk_f,na.rm=T)) %>% 
  left_join(meter_net) %>% 
  st_sf()

ggplot() +
  geom_sf(data = width_net, aes(fill = sidewalk_width), color = NA) +
  scale_fill_viridis() +
  labs(title = "Sidewalk Width in Fishnet Grids")+
    mapTheme()
```

### Joining neighborhood data to the fishnet

```{r Joining neighborhood data to the fishnett}
census_net <- st_join(meter_net,SF_census) %>% 
  dplyr::select(uniqueID,  Percent_White, Mean_Commute_Time, Percent_Taking_Public_Trans) %>% 
  st_drop_geometry() %>% 
  group_by(uniqueID) %>% 
  summarize(Percent_White=mean(Percent_White,na.rm=T),
            Mean_Commute_Time=mean(Mean_Commute_Time,na.rm=T),
            Percent_Taking_Public_Trans=mean(Percent_Taking_Public_Trans,na.rm=T)) %>% 
  left_join(meter_net) %>% 
  st_sf()

census_net %>% 
  dplyr::select(-Mean_Commute_Time) %>% 
  gather(-uniqueID,-geometry,key=variable,value=value) %>% 
  ggplot() +
    geom_sf(aes(fill = value)) +
    facet_wrap(~variable)+
    scale_fill_viridis() +
    labs(title = "Neighborhood Data in Fishnet Grids")+
    mapTheme()

census_net %>% 
  dplyr::select(Mean_Commute_Time) %>% 
  ggplot() +
    geom_sf(aes(fill = Mean_Commute_Time)) +
    scale_fill_viridis() +
    labs(title = "Neighborhood Data in Fishnet Grids")+
    mapTheme()
```

### Joining cleaning request to the fishnet

```{r Joining cleaning request to the fishnet}
clean_net <- street_clean %>% 
  mutate(count=1) %>% 
  st_join(meter_net,.) %>% 
  st_drop_geometry() %>% 
  group_by(uniqueID) %>% 
  summarize(countClean = sum(count,na.rm = T)) %>% 
  left_join(meter_net) %>%
  st_sf() 

ggplot() +
  geom_sf(data = clean_net, aes(fill = countClean), color = NA) +
  scale_fill_viridis() +
  labs(title = "Street Cleaning Request in Fishnet Grids")+
  mapTheme()
```

### Joining Graffiti to the fishnet

```{r Joining Graffiti to the fishnet}
graffiti_net <- graffiti %>% 
  mutate(count=1) %>% 
  st_join(meter_net,.) %>% 
  st_drop_geometry() %>% 
  group_by(uniqueID) %>% 
  summarize(countGraffiti = sum(count,na.rm = T)) %>% 
  left_join(meter_net) %>%
  st_sf() 

ggplot() +
  geom_sf(data = graffiti_net, aes(fill = countGraffiti), color = NA) +
  scale_fill_viridis() +
  labs(title = "Graffiti in Fishnet Grids")+
  mapTheme()
```

### Joining parking violation to the fishnet

```{r Joining parking violation to the fishnet}
parking_violation_net <- parking_violation %>% 
  mutate(count=1) %>% 
  st_join(meter_net,.) %>% 
  st_drop_geometry() %>% 
  group_by(uniqueID) %>% 
  summarize(countViolation = sum(count,na.rm = T)) %>% 
  left_join(meter_net) %>%
  st_sf() 

ggplot() +
  geom_sf(data = parking_violation_net, aes(fill = countViolation), color = NA) +
  scale_fill_viridis() +
  labs(title = "Parking Violation Request in Fishnet Grids")+
  mapTheme()
```

### Joining parking management district to the fishnet

fill_viridis() +

```{r Joining parking management district to the fishnet}
management_net <- st_join(st_centroid(meter_net),parking_district) %>% 
  st_drop_geometry() %>% 
  right_join(meter_net) %>% 
  st_sf() %>% 
  dplyr::select(uniqueID, pm_district_name)

ggplot() +
  geom_sf(data = management_net, aes(fill = pm_district_name), color = NA) +
  labs(title = "Parking Management District in Fishnet Grids")+
    mapTheme()
```

### 

### Joining shared car parking to the fishnet

```{r Joining shared car parking to the fishnet}
carshare_net <- careshare_park %>% 
  mutate(count=1) %>% 
  st_join(meter_net,.) %>% 
  st_drop_geometry() %>% 
  group_by(uniqueID) %>% 
  summarize(countCarshare = sum(count,na.rm = T)) %>% 
  left_join(meter_net) %>%
  st_sf() 

ggplot() +
  geom_sf(data = carshare_net, aes(fill = countCarshare), color = NA) +
  scale_fill_viridis() +
  labs(title = "Shared Car Parking in Fishnet Grids")+
  mapTheme()
```

### Joining retail spots to the fishnet

```{r Joining retail spots to the fishnet}
retail_net <- retail_spot %>% 
  mutate(count=1) %>% 
  st_join(meter_net,.) %>% 
  st_drop_geometry() %>% 
  group_by(uniqueID) %>% 
  summarize(countRetail = sum(count,na.rm = T)) %>% 
  left_join(meter_net) %>%
  st_sf() 

ggplot() +
  geom_sf(data = retail_net, aes(fill = countRetail), color = NA) +
  scale_fill_viridis() +
  labs(title = "Retail Spots in Fishnet Grids")+
  mapTheme()
```

### Joining food spots to the fishnet

```{r Joining food spots to the fishnet}
food_net <- food_spot %>% 
  mutate(count=1) %>% 
  st_join(meter_net,.) %>% 
  st_drop_geometry() %>% 
  group_by(uniqueID) %>% 
  summarize(countFood = sum(count,na.rm = T)) %>% 
  left_join(meter_net) %>%
  st_sf() 

ggplot() +
  geom_sf(data = food_net, aes(fill = countFood), color = NA) +
  scale_fill_viridis() +
  labs(title = "Food Spots in Fishnet Grids")+
  mapTheme()
```

### Combining all other factors into one fishnet

```{r Combining all factors into one fishnet}
centroid_fishnet <- st_centroid(meter_net) %>%
  dplyr::select(uniqueID, geometry)

# put all variables into fishnet
st_c <- st_coordinates
var_net <-
  parking_net %>% 
  dplyr::select(uniqueID, geometry, countPark) %>%
  mutate(
    off_parking.nn = nn_function(st_c(centroid_fishnet), st_c(off_parking_sf), 2)) %>% 
  left_join(carshare_net %>% st_drop_geometry(), by = "uniqueID") %>% 
  left_join(census_net %>% st_drop_geometry() , by = "uniqueID") %>% 
  left_join(clean_net %>% st_drop_geometry(), by = "uniqueID") %>% 
  left_join(food_net %>% st_drop_geometry(), by = "uniqueID") %>% 
  left_join(graffiti_net %>% st_drop_geometry(), by = "uniqueID") %>% 
  left_join(incident_net %>% st_drop_geometry(), by = "uniqueID") %>% 
  left_join(management_net %>% st_drop_geometry(), by = "uniqueID") %>% 
  left_join(parking_violation_net %>% st_drop_geometry(), by = "uniqueID") %>% 
  left_join(retail_net %>% st_drop_geometry(), by = "uniqueID") %>% 
  left_join(speed_net %>% st_drop_geometry(), by = "uniqueID") %>% 
  left_join(width_net %>% st_drop_geometry(), by = "uniqueID") 

```

### 

## Creating the space/time panel

```{r Creating the space/time panel}
# create space-time panel
street_parks.final <- street_parks_sf[sample(nrow(street_parks_sf),200000),]  

street_parks.final<- street_parks.final %>% 
  mutate(session_start_dt = ymd_hms(session_start_dt)) %>% 
  filter(hour(session_start_dt) >= 9 & hour(session_start_dt) <=18)

street_parks.final <- street_parks.final %>% 
  mutate(week = week(session_start_dt),
         dotw = wday(session_start_dt, label = TRUE),
         interval60 = floor_date(ymd_hms(session_start_dt), unit = "hour"),
         interval15 = floor_date(ymd_hms(session_start_dt), unit = "15 mins")) %>%
  merge(meters, by="post_id") %>% 
  dplyr::select(post_id, session_start_dt, gross_paid_amt, interval60, interval15)

street_park_grid <-
  st_join(var_net,street_parks.final) %>%
  na.omit() 

park.panel <- 
  expand.grid(interval60=unique(street_park_grid$interval60), 
              uniqueID = unique(street_park_grid$uniqueID)) 

park.panel.count <- 
  street_park_grid %>%
  st_drop_geometry() %>% 
  mutate(Park_Counter = 1) %>%
  right_join(park.panel,by=c("uniqueID","interval60")) %>% 
  group_by(interval60, uniqueID) %>%
  summarize(Real_Count = sum(Park_Counter, na.rm=T)) %>%
  ungroup() %>%
  mutate(week = week(interval60),
         dotw = wday(interval60, label = TRUE)) %>% 
  left_join(var_net) %>% 
  st_sf()

# park.panel.mean <- 
#   street_park_grid %>%
#   st_drop_geometry() %>% 
#   mutate(Park_Counter = 1) %>%
#   right_join(park.panel,by=c("uniqueID","interval15")) %>% 
#   group_by(interval15, uniqueID) %>%
#   summarize(Real_Count = sum(Park_Counter, na.rm=T)) %>%
#   ungroup() %>%
#   mutate(week = week(interval15),
#          dotw = wday(interval15, label = TRUE)) %>% 
#   left_join(meter_net) %>%
#   left_join(var_net) %>% 
#   mutate(mean = Real_Count/countMeters) %>%
#   st_sf() 

# add time lag to the panel
park.panel.lag <- 
  park.panel.count %>% 
  arrange(interval60, uniqueID) %>% 
  mutate(
         lagHour = dplyr::lag(Real_Count,1),
         lag2Hours = dplyr::lag(Real_Count,2),
         lag3Hours = dplyr::lag(Real_Count,3),
         lagDay = dplyr::lag(Real_Count,24)) %>%
  mutate(day = yday(interval60))

ggplot(park.panel.lag, aes(interval60, Real_Count)) + 
  geom_line() +
  scale_colour_manual(values = palette2) +
  labs(title="On-street Car Parks per hour, SF, 2021-07-09",
       x="Time", y="Number of Parking Records")
```

```{r Spliting data into train/test sets}
park.Train <- filter(park.panel.lag, week <= 32)
park.Test <- filter(park.panel.lag, week > 32)
```

```{r Creating linear models}
linear_reg7 <- 
  lm(log_count ~  hour(interval60) + dotw + uniqueID + lagHour + lag2Hours +lag3Hours + lagDay,  data=park.Train)

linear_reg8 <- 
  lm(log_count ~  hour(interval60) + dotw + uniqueID + lagHour + lag2Hours +lag3Hours + lagDay 
     + off_parking.nn + countCarshare + Percent_White + Mean_Commute_Time + Percent_Taking_Public_Trans
     + countClean + countFood + countGraffiti + countIncident + countViolation + countRetail
     + pm_district_name + speedlimit + sidewalk_width,
     data=park.Train)

# summary(linear_reg8)
```

```{r Testing accuracy of the models}
park.Test.weekNest <- 
  park.Test %>%
  nest(-week) 

model_pred <- function(dat, fit){
  pred <- predict(fit, newdata = dat)}

week_predictions <- 
  park.Test.weekNest %>% 
  mutate(
    #linear_MEAN = map(.x = data, fit = linear_reg1, .f = model_pred),
    #poisson_MEAN = map(.x = data, fit = poisson_reg1, .f = model_pred),
    #linear_COUNT = map(.x = data, fit = linear_reg2, .f = model_pred),
    #poisson_COUNT = map(.x = data, fit = poisson_reg2, .f = model_pred),
    #linear_logMEAN = map(.x = data, fit = linear_reg3, .f = model_pred),
    #poisson_logMEAN = map(.x = data, fit = poisson_reg3, .f = model_pred),
    linear_logCOUNT = map(.x = data, fit = linear_reg7, .f = model_pred),
    #poisson_logCOUNT = map(.x = data, fit = poisson_reg4, .f = model_pred),
    linear_all = map(.x = data, fit = linear_reg8, .f = model_pred),
  ) %>% 
  gather(Regression, Prediction, -data, -week) %>%
  mutate(Observed = map(data, pull, mean),
         Absolute_Error = map2(Observed, Prediction,  ~ abs(.x - .y)),
         MAE = map_dbl(Absolute_Error, mean, na.rm = TRUE),
         sd_AE = map_dbl(Absolute_Error, sd, na.rm = TRUE))

```

```{r A backup solution to check accuracy}
abs_error_reg7 <-
  abs(predict(linear_reg7, park.Test) - park.Test$log_count)
abs_error_reg8 <-
  abs(predict(linear_reg8, park.Test) - park.Test$log_count)
mean(abs_error_reg7)
mean(abs_error_reg8)
mean(park.Test$log_count)
```
